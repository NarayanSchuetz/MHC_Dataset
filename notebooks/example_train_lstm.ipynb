{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Import the MHC dataset and LSTM model\n",
    "from torch_dataset import BaseMhcDataset\n",
    "from models.lstm import AutoencoderLSTM, LSTMTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization_df = pd.read_csv(\"/scratch/users/schuetzn/data/mhc_dataset_out/standardization_params.csv\")\n",
    "\n",
    "scaler_stats = {}\n",
    "for f_idx, row in standardization_df.iloc[:6].iterrows():\n",
    "    scaler_stats[f_idx] = (row[\"mean\"], row[\"std_dev\"])\n",
    "\n",
    "scaler_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get input from user\n",
    "dataset_parquet_path = \"../test_dataset.parquet\"\n",
    "root_dir = \"/scratch/groups/euan/mhc/mhc_dataset\"\n",
    "\n",
    "print(f\"Loading dataset from {dataset_parquet_path}\")\n",
    "print(f\"Using root directory: {root_dir}\")\n",
    "\n",
    "# Load the denormalized dataset from parquet\n",
    "df = pd.read_parquet(dataset_parquet_path)\n",
    "df[\"file_uris\"] = df[\"file_uris\"].apply(eval)\n",
    "\n",
    "print(f\"Loaded dataset with {len(df)} samples\")\n",
    "\n",
    "# Print available label columns\n",
    "label_cols = [col for col in df.columns if col.endswith('_value')]\n",
    "print(f\"Available label columns: {label_cols}\")\n",
    "\n",
    "# Create the dataset with mask\n",
    "dataset = BaseMhcDataset(df, root_dir, include_mask=True, feature_stats=scaler_stats)\n",
    "\n",
    "# Split into train and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "print(f\"Split dataset into {train_size} training and {val_size} validation samples\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Initialize model\n",
    "# Set target_labels to None if there are no labels you want to predict\n",
    "# Or specify the labels you want to predict (without '_value' suffix)\n",
    "target_labels = [] #[label.replace('_value', '') for label in label_cols[:2]] if label_cols else None\n",
    "\n",
    "model = AutoencoderLSTM(\n",
    "    hidden_size=256,\n",
    "    encoding_dim=256,\n",
    "    num_layers=5,\n",
    "    dropout=0.1,\n",
    "    bidirectional=False,\n",
    "    target_labels=target_labels,\n",
    "    prediction_horizon=1,\n",
    "    use_masked_loss=True\n",
    ")\n",
    "print(f\"Initialized LSTM model with target labels: {target_labels}\")\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set up trainer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "trainer = LSTMTrainer(model, optimizer, device)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5  # Reduced for demonstration\n",
    "print(f\"Training for {num_epochs} epochs...\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = trainer.train_epoch(train_loader)\n",
    "    val_loss = trainer.validate(val_loader)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Make predictions on a sample\n",
    "print(\"Making predictions on a validation sample...\")\n",
    "with torch.no_grad():\n",
    "    # Get a sample from validation set\n",
    "    sample_idx = 0\n",
    "    sample = val_dataset[sample_idx]\n",
    "    \n",
    "    # Print metadata for the sample\n",
    "    print(f\"Sample metadata: {sample['metadata']}\")\n",
    "    \n",
    "    # Prepare batch format\n",
    "    batch = {\n",
    "        'data': sample['data'].unsqueeze(0).to(device),  # Add batch dimension\n",
    "        'mask': sample['mask'].unsqueeze(0).to(device)\n",
    "    }\n",
    "    \n",
    "    # Forward pass\n",
    "    model.eval()\n",
    "    output = model(batch)\n",
    "    \n",
    "    # Get predictions\n",
    "    predicted_segments = output['sequence_output'][0].cpu().numpy()  # Remove batch dimension\n",
    "    target_segments = output['target_segments'][0].cpu().numpy()\n",
    "    \n",
    "    # Visualize prediction for a single feature and segment\n",
    "    feature_idx = 0  # First feature\n",
    "    segment_idx = 0  # First segment\n",
    "    \n",
    "    # Extract the first 30 values\n",
    "    predicted_values = predicted_segments[segment_idx, :30]\n",
    "    target_values = target_segments[segment_idx, :30]\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(predicted_values, label='Predicted', marker='o')\n",
    "    plt.plot(target_values, label='Target', marker='x')\n",
    "    plt.xlabel('Time index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Prediction vs Target for Feature {feature_idx}, Segment {segment_idx}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "model, trainer  # Return model and trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
